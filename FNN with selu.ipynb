{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "dropout_input = 0.8\n",
    "dropout_hidden = 0.8\n",
    "batch_size = 256\n",
    "num_steps = 7000\n",
    "display_steps = 200\n",
    "beta = 0\n",
    "\n",
    "num_input = 28*28\n",
    "num_hidden1 = 500\n",
    "num_hidden2 = 500\n",
    "num_hidden3 = 500\n",
    "num_layers = 3\n",
    "num_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(x, weights, biases, dropout_input, dropout_hidden):\n",
    "    #reshape x back to be an image\n",
    "    #x = tf.reshape(x, [-1, 28, 28 ,1])\n",
    "    \n",
    "    layer1 = tf.matmul(x, weights['w1']) + biases['b1']\n",
    "    layer1 = tf.contrib.nn.alpha_dropout(tf.nn.selu(layer1), dropout_input)\n",
    "    \n",
    "    layer2 = tf.matmul(layer1, weights['w2']) + biases['b2']\n",
    "    layer2 = tf.contrib.nn.alpha_dropout(tf.nn.selu(layer2), dropout_hidden)\n",
    "    \n",
    "    layer3 = tf.matmul(layer2, weights['w3']) + biases['b3']\n",
    "    layer3 = tf.contrib.nn.alpha_dropout(tf.nn.selu(layer3), dropout_hidden)\n",
    "    \n",
    "    output = tf.matmul(layer3, weights['w_out']) + biases['b_out']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'w1': tf.get_variable('w1', shape=[num_input, num_hidden1], initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN')),\n",
    "    'w2': tf.get_variable('w2', shape=[num_hidden1, num_hidden2], initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN')),\n",
    "    'w3': tf.get_variable('w3', shape=[num_hidden2, num_hidden3], initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN')),\n",
    "    'w_out': tf.get_variable('w_out', shape=[num_hidden3, num_classes], initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN'))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.get_variable('b1', shape=[num_hidden1], initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN')),\n",
    "    'b2': tf.get_variable('b2', shape=[num_hidden2], initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN')),\n",
    "    'b3': tf.get_variable('b3', shape=[num_hidden3], initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN')),\n",
    "    'b_out': tf.get_variable('b_out', shape=[num_classes], initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN'))\n",
    "}\n",
    "\n",
    "logits = neural_net(X, weights, biases, dropout_input, dropout_hidden)\n",
    "\n",
    "regularizer = tf.nn.l2_loss(weights['w1']) + tf.nn.l2_loss(weights['w2']) + tf.nn.l2_loss(weights['w_out'])\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = Y) + beta * regularizer)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step1, Minibatch loss2.0238, Trainning accuracy0.367\n",
      "Step200, Minibatch loss0.3128, Trainning accuracy0.891\n",
      "Step400, Minibatch loss0.1298, Trainning accuracy0.965\n",
      "Step600, Minibatch loss0.1923, Trainning accuracy0.934\n",
      "Step800, Minibatch loss0.1357, Trainning accuracy0.957\n",
      "Step1000, Minibatch loss0.2793, Trainning accuracy0.914\n",
      "Step1200, Minibatch loss0.2754, Trainning accuracy0.949\n",
      "Step1400, Minibatch loss0.2165, Trainning accuracy0.938\n",
      "Step1600, Minibatch loss0.0702, Trainning accuracy0.977\n",
      "Step1800, Minibatch loss0.2064, Trainning accuracy0.961\n",
      "Step2000, Minibatch loss0.2929, Trainning accuracy0.938\n",
      "Step2200, Minibatch loss0.2101, Trainning accuracy0.949\n",
      "Step2400, Minibatch loss0.1467, Trainning accuracy0.953\n",
      "Step2600, Minibatch loss0.1782, Trainning accuracy0.941\n",
      "Step2800, Minibatch loss0.0435, Trainning accuracy0.984\n",
      "Step3000, Minibatch loss0.2079, Trainning accuracy0.953\n",
      "Step3200, Minibatch loss0.1668, Trainning accuracy0.973\n",
      "Step3400, Minibatch loss0.1479, Trainning accuracy0.961\n",
      "Step3600, Minibatch loss0.1885, Trainning accuracy0.949\n",
      "Step3800, Minibatch loss0.1798, Trainning accuracy0.953\n",
      "Step4000, Minibatch loss0.1231, Trainning accuracy0.953\n",
      "Step4200, Minibatch loss0.3482, Trainning accuracy0.965\n",
      "Step4400, Minibatch loss0.1807, Trainning accuracy0.961\n",
      "Step4600, Minibatch loss0.1127, Trainning accuracy0.965\n",
      "Step4800, Minibatch loss0.0420, Trainning accuracy0.988\n",
      "Step5000, Minibatch loss0.1367, Trainning accuracy0.961\n",
      "Step5200, Minibatch loss0.3539, Trainning accuracy0.949\n",
      "Step5400, Minibatch loss0.0895, Trainning accuracy0.973\n",
      "Step5600, Minibatch loss0.1495, Trainning accuracy0.949\n",
      "Step5800, Minibatch loss0.0977, Trainning accuracy0.973\n",
      "Step6000, Minibatch loss0.0523, Trainning accuracy0.980\n",
      "Step6200, Minibatch loss0.2337, Trainning accuracy0.957\n",
      "Step6400, Minibatch loss0.0817, Trainning accuracy0.977\n",
      "Step6600, Minibatch loss0.1147, Trainning accuracy0.969\n",
      "Step6800, Minibatch loss0.1245, Trainning accuracy0.961\n",
      "Step7000, Minibatch loss0.1013, Trainning accuracy0.984\n",
      "Optimization done!\n",
      "Test accuracy: 0.9615\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        sess.run(train_op, feed_dict = {X: batch_x, Y:batch_y})\n",
    "        \n",
    "        if step % display_steps == 0 or step == 1:\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict = {X: batch_x, Y:batch_y})\n",
    "            print(\"Step\" + str(step) + \", Minibatch loss\" +\"{:.4f}\".format(loss) + \", Trainning accuracy\" + \"{:.3f}\".format(acc))\n",
    "    \n",
    "    print(\"Optimization done!\")\n",
    "    \n",
    "    test_accu = sess.run(accuracy, feed_dict = {X: mnist.test.images, Y:mnist.test.labels})\n",
    "    \n",
    "    print(\"Test accuracy:\", test_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
