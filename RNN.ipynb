{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_steps = 10000\n",
    "batch_size = 128\n",
    "display_step = 200\n",
    "\n",
    "num_inputs = 28\n",
    "timesteps = 28\n",
    "num_units = 128\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, timesteps, num_inputs])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_units, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_units, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 200 minibatch loss 1.1572338 minibatch accuracy 0.6328125\n",
      "iter 400 minibatch loss 0.8960469 minibatch accuracy 0.75\n",
      "iter 600 minibatch loss 0.64494306 minibatch accuracy 0.8125\n",
      "iter 800 minibatch loss 0.4541263 minibatch accuracy 0.890625\n",
      "iter 1000 minibatch loss 0.453861 minibatch accuracy 0.859375\n",
      "iter 1200 minibatch loss 0.35250735 minibatch accuracy 0.8984375\n",
      "iter 1400 minibatch loss 0.37073123 minibatch accuracy 0.8671875\n",
      "iter 1600 minibatch loss 0.32649475 minibatch accuracy 0.875\n",
      "iter 1800 minibatch loss 0.23312849 minibatch accuracy 0.9375\n",
      "iter 2000 minibatch loss 0.20754817 minibatch accuracy 0.9296875\n",
      "iter 2200 minibatch loss 0.14087595 minibatch accuracy 0.9609375\n",
      "iter 2400 minibatch loss 0.13877735 minibatch accuracy 0.9609375\n",
      "iter 2600 minibatch loss 0.1724372 minibatch accuracy 0.9453125\n",
      "iter 2800 minibatch loss 0.19115505 minibatch accuracy 0.921875\n",
      "iter 3000 minibatch loss 0.15169433 minibatch accuracy 0.9609375\n",
      "iter 3200 minibatch loss 0.14120626 minibatch accuracy 0.9375\n",
      "iter 3400 minibatch loss 0.12973449 minibatch accuracy 0.953125\n",
      "iter 3600 minibatch loss 0.069016404 minibatch accuracy 0.9921875\n",
      "iter 3800 minibatch loss 0.11245629 minibatch accuracy 0.96875\n",
      "iter 4000 minibatch loss 0.09442423 minibatch accuracy 0.953125\n",
      "iter 4200 minibatch loss 0.056612425 minibatch accuracy 1.0\n",
      "iter 4400 minibatch loss 0.08666812 minibatch accuracy 0.984375\n",
      "iter 4600 minibatch loss 0.08348986 minibatch accuracy 0.9609375\n",
      "iter 4800 minibatch loss 0.050272163 minibatch accuracy 0.984375\n",
      "iter 5000 minibatch loss 0.07425465 minibatch accuracy 0.9765625\n",
      "iter 5200 minibatch loss 0.07476118 minibatch accuracy 0.96875\n",
      "iter 5400 minibatch loss 0.08463694 minibatch accuracy 0.9765625\n",
      "iter 5600 minibatch loss 0.08734734 minibatch accuracy 0.96875\n",
      "iter 5800 minibatch loss 0.023080962 minibatch accuracy 1.0\n",
      "iter 6000 minibatch loss 0.058953658 minibatch accuracy 0.984375\n",
      "iter 6200 minibatch loss 0.04863118 minibatch accuracy 0.984375\n",
      "iter 6400 minibatch loss 0.0701364 minibatch accuracy 0.984375\n",
      "iter 6600 minibatch loss 0.052095927 minibatch accuracy 0.9921875\n",
      "iter 6800 minibatch loss 0.04232712 minibatch accuracy 0.9921875\n",
      "iter 7000 minibatch loss 0.09358977 minibatch accuracy 0.9765625\n",
      "iter 7200 minibatch loss 0.08934015 minibatch accuracy 0.9609375\n",
      "iter 7400 minibatch loss 0.03298716 minibatch accuracy 0.9921875\n",
      "iter 7600 minibatch loss 0.09339673 minibatch accuracy 0.9765625\n",
      "iter 7800 minibatch loss 0.05615121 minibatch accuracy 0.9921875\n",
      "iter 8000 minibatch loss 0.025461255 minibatch accuracy 1.0\n",
      "iter 8200 minibatch loss 0.026912853 minibatch accuracy 1.0\n",
      "iter 8400 minibatch loss 0.04676015 minibatch accuracy 0.9921875\n",
      "iter 8600 minibatch loss 0.032314256 minibatch accuracy 0.9921875\n",
      "iter 8800 minibatch loss 0.05747404 minibatch accuracy 0.984375\n",
      "iter 9000 minibatch loss 0.041443486 minibatch accuracy 0.9921875\n",
      "iter 9200 minibatch loss 0.08192985 minibatch accuracy 0.96875\n",
      "iter 9400 minibatch loss 0.023338977 minibatch accuracy 1.0\n",
      "iter 9600 minibatch loss 0.02615237 minibatch accuracy 0.9921875\n",
      "iter 9800 minibatch loss 0.06082826 minibatch accuracy 0.984375\n",
      "iter 10000 minibatch loss 0.016204542 minibatch accuracy 1.0\n",
      "training finished!\n",
      "Testing Accuracy: 0.984375\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for steps in range(1, training_steps+1):\n",
    "        x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        x_batch = x_batch.reshape((batch_size, timesteps, num_inputs))\n",
    "        sess.run([train_op], feed_dict = {X: x_batch, Y: y_batch})\n",
    "        \n",
    "        if steps %200 == 0:\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict = {X: x_batch, Y: y_batch})\n",
    "            print(\"iter\", steps, \"minibatch loss\", loss, \"minibatch accuracy\", acc)\n",
    "    \n",
    "    print(\"training finished!\")\n",
    "    \n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_inputs))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
