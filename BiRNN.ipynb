{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_steps = 10000\n",
    "batch_size = 128\n",
    "steps_print = 200\n",
    "\n",
    "num_input = 28\n",
    "timesteps = 28\n",
    "num_hidden = 128\n",
    "num_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, timesteps, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiRNN(x, weights, biases):\n",
    "    \n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "    \n",
    "    lstm_fw = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    lstm_bw = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "    outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw, lstm_bw, x, dtype=tf.float32)\n",
    "    \n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([2 * num_hidden, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-7351db16b791>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logits = BiRNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200 minibatch loss 0.15712988 minibatch accuracy 0.9296875\n",
      "step 400 minibatch loss 0.055097338 minibatch accuracy 0.984375\n",
      "step 600 minibatch loss 0.12162349 minibatch accuracy 0.9765625\n",
      "step 800 minibatch loss 0.01288471 minibatch accuracy 1.0\n",
      "step 1000 minibatch loss 0.060132697 minibatch accuracy 0.984375\n",
      "step 1200 minibatch loss 0.02557467 minibatch accuracy 0.9921875\n",
      "step 1400 minibatch loss 0.050713725 minibatch accuracy 0.9921875\n",
      "step 1600 minibatch loss 0.020397581 minibatch accuracy 0.9921875\n",
      "step 1800 minibatch loss 0.014675704 minibatch accuracy 1.0\n",
      "step 2000 minibatch loss 0.016424345 minibatch accuracy 1.0\n",
      "step 2200 minibatch loss 0.026160851 minibatch accuracy 0.9921875\n",
      "step 2400 minibatch loss 0.0041245036 minibatch accuracy 1.0\n",
      "step 2600 minibatch loss 0.011448875 minibatch accuracy 1.0\n",
      "step 2800 minibatch loss 0.036928743 minibatch accuracy 0.9921875\n",
      "step 3000 minibatch loss 0.011150962 minibatch accuracy 1.0\n",
      "step 3200 minibatch loss 0.008506944 minibatch accuracy 1.0\n",
      "step 3400 minibatch loss 0.034454834 minibatch accuracy 0.9921875\n",
      "step 3600 minibatch loss 0.013916982 minibatch accuracy 1.0\n",
      "step 3800 minibatch loss 0.012123763 minibatch accuracy 1.0\n",
      "step 4000 minibatch loss 0.013344417 minibatch accuracy 0.9921875\n",
      "step 4200 minibatch loss 0.013412736 minibatch accuracy 0.9921875\n",
      "step 4400 minibatch loss 0.011820236 minibatch accuracy 1.0\n",
      "step 4600 minibatch loss 0.0055198204 minibatch accuracy 1.0\n",
      "step 4800 minibatch loss 0.005835566 minibatch accuracy 1.0\n",
      "step 5000 minibatch loss 0.019686466 minibatch accuracy 0.9921875\n",
      "step 5200 minibatch loss 0.0020685876 minibatch accuracy 1.0\n",
      "step 5400 minibatch loss 0.003822865 minibatch accuracy 1.0\n",
      "step 5600 minibatch loss 0.006211556 minibatch accuracy 1.0\n",
      "step 5800 minibatch loss 0.0033320184 minibatch accuracy 1.0\n",
      "step 6000 minibatch loss 0.00889921 minibatch accuracy 1.0\n",
      "step 6200 minibatch loss 0.0027875497 minibatch accuracy 1.0\n",
      "step 6400 minibatch loss 0.0035837796 minibatch accuracy 1.0\n",
      "step 6600 minibatch loss 0.008241738 minibatch accuracy 1.0\n",
      "step 6800 minibatch loss 0.026048338 minibatch accuracy 0.9921875\n",
      "step 7000 minibatch loss 0.011543816 minibatch accuracy 0.9921875\n",
      "step 7200 minibatch loss 0.012345316 minibatch accuracy 1.0\n",
      "step 7400 minibatch loss 0.018889839 minibatch accuracy 0.9921875\n",
      "step 7600 minibatch loss 0.00297159 minibatch accuracy 1.0\n",
      "step 7800 minibatch loss 0.0060223453 minibatch accuracy 1.0\n",
      "step 8000 minibatch loss 0.028033076 minibatch accuracy 0.9921875\n",
      "step 8200 minibatch loss 0.011110993 minibatch accuracy 1.0\n",
      "step 8400 minibatch loss 0.0042810114 minibatch accuracy 1.0\n",
      "step 8600 minibatch loss 0.004869433 minibatch accuracy 1.0\n",
      "step 8800 minibatch loss 0.0026836875 minibatch accuracy 1.0\n",
      "step 9000 minibatch loss 0.008890307 minibatch accuracy 1.0\n",
      "step 9200 minibatch loss 0.008090154 minibatch accuracy 1.0\n",
      "step 9400 minibatch loss 0.010541942 minibatch accuracy 1.0\n",
      "step 9600 minibatch loss 0.005212711 minibatch accuracy 1.0\n",
      "step 9800 minibatch loss 0.0051122233 minibatch accuracy 1.0\n",
      "step 10000 minibatch loss 0.0066383183 minibatch accuracy 1.0\n",
      "training finished!\n",
      "Testing Accuracy: 0.9921875\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x = batch_x.reshape([-1, timesteps, num_input])\n",
    "        \n",
    "        sess.run([train_op], feed_dict = {X:batch_x, Y:batch_y})\n",
    "        \n",
    "        if step % steps_print == 0:\n",
    "            loss, accu = sess.run([loss_op, accuracy], feed_dict = {X:batch_x, Y:batch_y})\n",
    "            print(\"step\", step, \"minibatch loss\", loss, \"minibatch accuracy\", accu)\n",
    "            \n",
    "    print(\"training finished!\")\n",
    "    \n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
